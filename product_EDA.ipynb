{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af69552-4bf2-4cc0-a273-b3aaab17cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896355ca-9e77-4402-8f77-328ee1db1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.sephora.com'\n",
    "crawl_delay=6\n",
    "DRIVER_PATH = '../../chromedriver_mac64/chromedriver'\n",
    "data_dir = \"data/\"\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "options.add_argument(\"--window-size=1920,1200\")\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "options.add_argument('user-agent={0}'.format(user_agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44aff2-2dde-4d3e-bdff-3b28d9bd3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sku(soup) -> str:\n",
    "    \"\"\"\n",
    "    Returns sku code from product page in format 'Item #######'\n",
    "    \"\"\"\n",
    "    return soup.find('p', attrs={'data-at':'item-sku'}).text    \n",
    "\n",
    "\n",
    "def get_breadcrumb_categories(soup) -> List:\n",
    "    \"\"\"\n",
    "    Returns list of categorical values used to describe product in header of product page\n",
    "        for ex. ['Skincare','Moisturizer']\n",
    "    \"\"\"\n",
    "    return [x.text for x in soup.find('nav', attrs={'data-comp':\"ProductBreadCrumbs BreadCrumbs BreadCrumbs \"}).findAll('li')]\n",
    "\n",
    "\n",
    "def get_brand_name(soup) -> str:\n",
    "    \"\"\"\n",
    "    Returns product brand name from product page\n",
    "    \"\"\"\n",
    "    return soup.find(\"a\", attrs={'data-at':\"brand_name\"}).text\n",
    "\n",
    "\n",
    "def get_product_name(soup) -> str:\n",
    "    \"\"\"\n",
    "    Returns product name as written on product page\n",
    "    \"\"\"\n",
    "    return soup.find(\"span\", attrs={'data-at':\"product_name\"}).text\n",
    "\n",
    "\n",
    "def get_num_loves(soup) -> str:\n",
    "    \"\"\"\n",
    "    Returns number of 'love' votes for product\n",
    "        loves seem to be used to track product frequently repurchased\n",
    "    \"\"\"\n",
    "    return soup.find(\"div\", attrs={\"data-comp\": \"LovesCount \"}).span.text\n",
    "\n",
    "\n",
    "def get_ingredients(soup) -> str:\n",
    "    \"\"\"\n",
    "    Returns full ingredient list as blob of text\n",
    "    \"\"\"\n",
    "    return soup.find_all(\"div\", {\"id\": \"ingredients\"})[0].text\n",
    "\n",
    "\n",
    "def get_rating_data(soup) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "        Sephora product page displays a 1-5 bar histogram of votes but it is difficult to retrieve the histogram data\n",
    "        ******might be able to figure this out later\n",
    "        Returns star rating and number of reviews as tuple\n",
    "    \"\"\"\n",
    "    rr_container = soup.find(\"a\", {\"href\": \"#ratings-reviews-container\"})\n",
    "    star_rating = rr_container.find(\"span\", {\"data-comp\":\"StarRating \"})['aria-label']\n",
    "    num_reviews = rr_container.text\n",
    "    return star_rating, num_reviews\n",
    "    \n",
    "    \n",
    "def get_product_buttons(soup) -> Dict:\n",
    "    \"\"\"\n",
    "    Products with mutliple size options will have different volume - price options\n",
    "    Returns all product options with class value included\n",
    "        Class is used to click buttons with selenium to fetch price for each option\n",
    "    \"\"\"\n",
    "    size_options = []\n",
    "    for prod_option in soup.find_all(\"div\", attrs={\"data-comp\":\"SwatchGroup \"}):\n",
    "        selected = {}\n",
    "        selected[\"name\"] = prod_option.find(\"p\").text\n",
    "        selected[\"size\"] = prod_option.button()[0].text\n",
    "        selected[\"class\"] = prod_option.find(\"button\")['class'][0]\n",
    "        size_options.append(selected)\n",
    "    return size_options\n",
    "\n",
    "\n",
    "def get_all_brands(soup):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # collecting brand names and links from brand list page \n",
    "    brand_data = []\n",
    "    for brand_link in soup.findAll('a', attrs={\"data-at\": \"brand_link\"}):\n",
    "        brand = {}\n",
    "        brand['name'] = brand_link.span.text\n",
    "        brand['link'] = brand_link.get('href') \n",
    "        brand_data.append(brand)\n",
    "    return brand_data\n",
    "\n",
    "\n",
    "def get_brand_products():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755e0eb-4a14-4351-b051-07e38723759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting brand names and links from brand list page \n",
    "driver = webdriver.Chrome(options=options, executable_path=DRIVER_PATH)\n",
    "url = \"https://www.sephora.com/ca/en/brands-list\"\n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "driver.quit()\n",
    "brand_data = get_all_brands(soup)\n",
    "# save brands \n",
    "pd.DataFrame(brand_data).to_csv(data_dir+'brand_list.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de45bb8-5162-4faa-87a3-7643d293bf5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_counter = 0\n",
    "# # for each brand, grab products on brand page, save products as list of links \n",
    "for brand in brand_data:\n",
    "    print(brand['name'])\n",
    "    url = base_url+brand['link']\n",
    "    product_urls = []\n",
    "    driver = webdriver.Chrome(options=options, executable_path=DRIVER_PATH)\n",
    "    driver.get(url)\n",
    "    #https://stackoverflow.com/questions/20986631/how-can-i-scroll-a-web-page-using-selenium-webdriver-in-python\n",
    "    SCROLL_PAUSE_TIME = 0.5\n",
    "    y=0\n",
    "\n",
    "    # Get scroll height\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    print(\"Expecting \", soup.find(\"p\", attrs={'data-at':'number_of_products'}).getText())\n",
    "    \n",
    "    products_on_load = soup.find_all('a', attrs={'data-comp':\"ProductTile \"}, href=True)\n",
    "    product_urls.extend([prod['href'].split(\" \")[0] for prod in products_on_load])\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        lazy_products = driver.find_elements_by_xpath('//a[@data-comp=\"LazyLoad ProductTile \"]')\n",
    "        product_urls.extend([prod.get_attribute('href') for prod in lazy_products])\n",
    "        # Scroll down\n",
    "        driver.execute_script(\"window.scrollTo(0, \"+str(y)+\");\")\n",
    "        y+=1000\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height < y:# last_height:\n",
    "            try:\n",
    "                # End of page if 'show more' button exists\n",
    "                driver.find_element(By.XPATH, \"//button[@class='css-bk5oor eanm77i0']\").click()\n",
    "            except:\n",
    "                # End of pages\n",
    "                product_urls.extend([prod.get_attribute('href') for prod in driver.find_elements_by_xpath('//a[@data-comp=\"LazyLoad ProductTile \"]')])\n",
    "                break\n",
    "        last_height = new_height    \n",
    "    brand['products'] = list(set(product_urls))\n",
    "    print(\"Retrieved \", len(brand['products']))\n",
    "    driver.quit()\n",
    "    time.sleep(crawl_delay)\n",
    "    # Serializing json\n",
    "    json_object = json.dumps(brand_data, indent=4)\n",
    "    with open(data_dir+\"brand_data.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "    if test_counter%16==0:\n",
    "        print(test_counter)\n",
    "    test_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f305a5-88de-401f-9723-b24b3a924b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_brands = ['Tom Ford', 'tarte', 'Moroccanoil', 'Dior', 'Anastasia Beverly Hills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927e6e5-42e0-479d-b769-f1676b070a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value kits will need to be separate or excluded...\n",
    "\n",
    "for brand in brand_data: \n",
    "    product_data = []    \n",
    "    for url in brand[\"products\"]:\n",
    "        time.sleep(crawl_delay)\n",
    "\n",
    "        # url = 'https://www.sephora.com/ca/en/product/charlotte-tilbury-airbrush-flawless-setting-spray-P461147?skuId=2368439&icid2=products%20grid:p461147:product'\n",
    "        product = {}\n",
    "        product[\"url\"] = url\n",
    "\n",
    "        # get class names of buttons and grab prices with selenium \n",
    "        driver = webdriver.Chrome(options=options, executable_path=DRIVER_PATH)\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        option_buttons = get_product_buttons(soup)\n",
    "        for button_info in option_buttons:\n",
    "            button_element = driver.find_element(By.XPATH, \"//button[@class='\"+button_info['class']+\"']\")\n",
    "            button_element.click()\n",
    "            button_info['price'] = driver.find_element(By.XPATH, \"//b[@class='css-0']\").text\n",
    "\n",
    "        driver.quit()\n",
    "        print(product)\n",
    "        if soup.find_all('h1') is not None and soup.find('h1').text != 'Sorry, this product is not available.':\n",
    "            product[\"product_name\"] = get_product_name(soup)\n",
    "            product[\"brand_name\"] = get_brand_name(soup)\n",
    "            product[\"options\"] = option_buttons\n",
    "            # product[\"description\"] = get_description(soup)\n",
    "            product[\"rating\"], product[\"n_reviews\"] = get_rating_data(soup)\n",
    "            product[\"ingredients\"] = get_ingredients(soup)\n",
    "            product[\"n_loves\"] = get_num_loves(soup)\n",
    "            product[\"categories\"] = get_breadcrumb_categories(soup)\n",
    "            product_data.append(product)\n",
    "            brand['product_data'] = product_data\n",
    "            brand['sku'] = get_sku(soup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
